{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af7ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c94958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling biomarkers\n",
    "bloodbiomk1_file_path = r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\bloodbiomk1_20231117.csv\"\n",
    "bloodbiomk1 = pd.read_csv(bloodbiomk1_file_path)\n",
    "bloodbiomk1 = pd.DataFrame(bloodbiomk1)\n",
    "\n",
    "bloodbiomk2_file_path = r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\bloodbiomk2_20231117.csv\"\n",
    "bloodbiomk2 = pd.read_csv(bloodbiomk2_file_path)\n",
    "bloodbiomk2 = pd.DataFrame(bloodbiomk2)\n",
    "\n",
    "csfbiomk1_file_path = r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\csfbiomk1_20231117.csv\"\n",
    "csfbiomk1 = pd.read_csv(csfbiomk1_file_path)\n",
    "csfbiomk1 = pd.DataFrame(csfbiomk1)\n",
    "\n",
    "csfbiomk2_file_path = r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\csfbiomk2_20231117.csv\"\n",
    "csfbiomk2 = pd.read_csv(csfbiomk2_file_path)\n",
    "csfbiomk2 = pd.DataFrame(csfbiomk2)\n",
    "\n",
    "csfbiomk3_file_path = r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\csfbiomk3_20231117.csv\"\n",
    "csfbiomk3 = pd.read_csv(csfbiomk3_file_path)\n",
    "csfbiomk3 = pd.DataFrame(csfbiomk3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae0e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "main_path = r'Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers'\n",
    "folder_name = 'blood_biomk1_to_briefa'  \n",
    "save_path = os.path.join(main_path, folder_name)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# save_path = r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\blood_biomk1_briefa\" # Update this path to your desired folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c104242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in csfbiomk1:\n",
      "                           Column  Number of Nulls\n",
      "0                      subject_id                0\n",
      "1                           visit                0\n",
      "2                     checkin_bin                0\n",
      "3                     exposurebin                0\n",
      "4                      age_decade                0\n",
      "5                racecat_combined                0\n",
      "6                        eduyears                0\n",
      "7                      totyr_foot               56\n",
      "8                     chiiseas_pf               56\n",
      "9                      chiiyrs_pf               56\n",
      "10                    chiiseas_pl               56\n",
      "11                     chiiyrs_pl               56\n",
      "12                    chiiseas_pg               56\n",
      "13                     chiiyrs_pg               56\n",
      "14     c_strem2_FLAG_insufficient               53\n",
      "15  c_PDGFRbeta_FLAG_insufficient               53\n",
      "16                       c_strem2               55\n",
      "17                    c_PDGFRbeta               56\n",
      "18                         c_Ab40               53\n",
      "19                         c_Ab42               53\n",
      "20                        c_pT181               53\n",
      "21    c_tTau_FLAG_below_ref_range               53\n",
      "22               c_FLAG_hemolysis               53\n",
      "23       c_tTau_FLAG_insufficient               53\n",
      "24                         c_ttau               67\n",
      "25                          c_NfL               53\n",
      "26                         c_GFAP               70\n",
      "27                        c_pT231               70\n",
      "28                        c_pT217               62\n",
      "29      dxcte_ptau217_csf_flag_dv               56\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in each column\n",
    "csfbiomk1_nulls = csfbiomk1.isnull().sum()\n",
    "\n",
    "csfbiomk1_nulls_df = pd.DataFrame({\n",
    "    'Column': csfbiomk1_nulls.index,\n",
    "    'Number of Nulls': csfbiomk1_nulls.values\n",
    "})\n",
    "\n",
    "csfbiomk1_nulls_df_transposed = csfbiomk1_nulls_df.T\n",
    "\n",
    "print(\"Null values in csfbiomk1:\")\n",
    "print(csfbiomk1_nulls_df)\n",
    "csfbiomk1_nulls_df_transposed.to_csv(r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\csfbiomk1_nulls.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36b7962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id  visit  checkin_bin  exposurebin  age_decade  racecat_combined  \\\n",
      "0      1001.0      1            2            1         1.0               5.0   \n",
      "1      1002.0      1            2            1         1.0               5.0   \n",
      "2      1003.0      1            2            1         1.0               5.0   \n",
      "3      1004.0      1            1            1         2.0               5.0   \n",
      "4      1005.0      1            3            0         2.0               5.0   \n",
      "\n",
      "   eduyears  totyr_foot  chiiseas_pf  chiiyrs_pf  ...    c_pT181  \\\n",
      "0      16.0         7.0       4335.4      2167.7  ...  24.400000   \n",
      "1      15.0        14.0      10363.1      5708.1  ...  32.220000   \n",
      "2      18.0        12.0       6685.4      4863.9  ...  32.220000   \n",
      "3      16.0        16.0       7701.2      6448.9  ...  39.058000   \n",
      "4      21.0         NaN          NaN         NaN  ...  38.311628   \n",
      "\n",
      "   c_tTau_FLAG_below_ref_range  c_FLAG_hemolysis  c_tTau_FLAG_insufficient  \\\n",
      "0                     0.000000          0.000000                      0.00   \n",
      "1                     0.075000          0.025000                      0.00   \n",
      "2                     0.075000          0.025000                      0.00   \n",
      "3                     0.060000          0.010000                      0.01   \n",
      "4                     0.093023          0.023256                      0.00   \n",
      "\n",
      "       c_ttau       c_NfL       c_GFAP     c_pT231   c_pT217  \\\n",
      "0  598.000000  373.960000  8706.690000  487.340000  0.605900   \n",
      "1  401.702703  735.907250  8163.845946  501.851892  1.254549   \n",
      "2  401.702703  735.907250  8163.845946  501.851892  1.254549   \n",
      "3  418.709677  780.569900  9070.057586  614.922874  2.080534   \n",
      "4  393.948718  756.707209  8165.744286  525.304762  1.457107   \n",
      "\n",
      "   dxcte_ptau217_csf_flag_dv  \n",
      "0                   1.000000  \n",
      "1                   1.100000  \n",
      "2                   1.100000  \n",
      "3                   1.175258  \n",
      "4                   1.093023  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean for each column, ignoring NaNs\n",
    "# Replace nulls with label means\n",
    "\n",
    "for column in csfbiomk1.columns:\n",
    "    if column != 'checkin_bin':  # Skip the label column\n",
    "\n",
    "        averages = csfbiomk1.groupby('checkin_bin')[column].mean()\n",
    "        \n",
    "        # Replace nulls for each label separately\n",
    "        for label in averages.index:\n",
    "            csfbiomk1.loc[(csfbiomk1['checkin_bin'] == label) & (csfbiomk1[column].isnull()), column] = averages[label]\n",
    "\n",
    "print(csfbiomk1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96806396",
   "metadata": {},
   "outputs": [],
   "source": [
    "csfbiomk1.to_csv(r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\csfbiomk1_nullreplaced.csv\")\n",
    "original_data = csfbiomk1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f107621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 236 entries, 0 to 235\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   c_strem2     236 non-null    float64\n",
      " 1   c_PDGFRbeta  236 non-null    float64\n",
      " 2   c_Ab40       236 non-null    float64\n",
      " 3   c_Ab42       236 non-null    float64\n",
      " 4   c_pT181      236 non-null    float64\n",
      " 5   c_ttau       236 non-null    float64\n",
      " 6   c_NfL        236 non-null    float64\n",
      " 7   c_GFAP       236 non-null    float64\n",
      " 8   c_pT231      236 non-null    float64\n",
      " 9   c_pT217      236 non-null    float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 18.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_strem2</th>\n",
       "      <th>c_PDGFRbeta</th>\n",
       "      <th>c_Ab40</th>\n",
       "      <th>c_Ab42</th>\n",
       "      <th>c_pT181</th>\n",
       "      <th>c_ttau</th>\n",
       "      <th>c_NfL</th>\n",
       "      <th>c_GFAP</th>\n",
       "      <th>c_pT231</th>\n",
       "      <th>c_pT217</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2035.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>8046.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>373.960000</td>\n",
       "      <td>8706.690000</td>\n",
       "      <td>487.340000</td>\n",
       "      <td>0.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2397.612245</td>\n",
       "      <td>361.773196</td>\n",
       "      <td>9599.500000</td>\n",
       "      <td>790.090000</td>\n",
       "      <td>39.058000</td>\n",
       "      <td>418.709677</td>\n",
       "      <td>780.569900</td>\n",
       "      <td>9070.057586</td>\n",
       "      <td>614.922874</td>\n",
       "      <td>2.080534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2752.976744</td>\n",
       "      <td>410.348837</td>\n",
       "      <td>11663.651163</td>\n",
       "      <td>964.255814</td>\n",
       "      <td>38.311628</td>\n",
       "      <td>393.948718</td>\n",
       "      <td>756.707209</td>\n",
       "      <td>8165.744286</td>\n",
       "      <td>525.304762</td>\n",
       "      <td>1.457107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      c_strem2  c_PDGFRbeta        c_Ab40      c_Ab42    c_pT181      c_ttau  \\\n",
       "0  2035.000000   295.000000   8046.000000  702.000000  24.400000  598.000000   \n",
       "1  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
       "2  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
       "3  2397.612245   361.773196   9599.500000  790.090000  39.058000  418.709677   \n",
       "4  2752.976744   410.348837  11663.651163  964.255814  38.311628  393.948718   \n",
       "\n",
       "        c_NfL       c_GFAP     c_pT231   c_pT217  \n",
       "0  373.960000  8706.690000  487.340000  0.605900  \n",
       "1  735.907250  8163.845946  501.851892  1.254549  \n",
       "2  735.907250  8163.845946  501.851892  1.254549  \n",
       "3  780.569900  9070.057586  614.922874  2.080534  \n",
       "4  756.707209  8165.744286  525.304762  1.457107  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csfbiomk1 = csfbiomk1.drop(columns=csfbiomk1.loc[:,'subject_id':'chiiyrs_pg'].columns)\n",
    "csfbiomk1 = csfbiomk1.drop(columns='c_strem2_FLAG_insufficient')\n",
    "csfbiomk1 = csfbiomk1.drop(columns=['c_PDGFRbeta_FLAG_insufficient',\n",
    "                              'c_tTau_FLAG_below_ref_range',\n",
    "                              'c_FLAG_hemolysis', \n",
    "                              'c_tTau_FLAG_insufficient',\n",
    "                              'dxcte_ptau217_csf_flag_dv'])\n",
    "csfbiomk1.info()\n",
    "csfbiomk1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d355d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_strem2</th>\n",
       "      <th>c_PDGFRbeta</th>\n",
       "      <th>c_Ab40</th>\n",
       "      <th>c_Ab42</th>\n",
       "      <th>c_pT181</th>\n",
       "      <th>c_ttau</th>\n",
       "      <th>c_NfL</th>\n",
       "      <th>c_GFAP</th>\n",
       "      <th>c_pT231</th>\n",
       "      <th>c_pT217</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2035.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>8046.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>373.960000</td>\n",
       "      <td>8706.690000</td>\n",
       "      <td>487.340000</td>\n",
       "      <td>0.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2397.612245</td>\n",
       "      <td>361.773196</td>\n",
       "      <td>9599.500000</td>\n",
       "      <td>790.090000</td>\n",
       "      <td>39.058000</td>\n",
       "      <td>418.709677</td>\n",
       "      <td>780.569900</td>\n",
       "      <td>9070.057586</td>\n",
       "      <td>614.922874</td>\n",
       "      <td>2.080534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2752.976744</td>\n",
       "      <td>410.348837</td>\n",
       "      <td>11663.651163</td>\n",
       "      <td>964.255814</td>\n",
       "      <td>38.311628</td>\n",
       "      <td>393.948718</td>\n",
       "      <td>756.707209</td>\n",
       "      <td>8165.744286</td>\n",
       "      <td>525.304762</td>\n",
       "      <td>1.457107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2397.612245</td>\n",
       "      <td>361.773196</td>\n",
       "      <td>9599.500000</td>\n",
       "      <td>790.090000</td>\n",
       "      <td>39.058000</td>\n",
       "      <td>418.709677</td>\n",
       "      <td>780.569900</td>\n",
       "      <td>9070.057586</td>\n",
       "      <td>614.922874</td>\n",
       "      <td>0.977400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4626.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>11797.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>1075.590000</td>\n",
       "      <td>37506.300000</td>\n",
       "      <td>609.430000</td>\n",
       "      <td>0.481200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2397.612245</td>\n",
       "      <td>361.773196</td>\n",
       "      <td>9599.500000</td>\n",
       "      <td>790.090000</td>\n",
       "      <td>39.058000</td>\n",
       "      <td>418.709677</td>\n",
       "      <td>780.569900</td>\n",
       "      <td>9070.057586</td>\n",
       "      <td>614.922874</td>\n",
       "      <td>2.080534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      c_strem2  c_PDGFRbeta        c_Ab40      c_Ab42    c_pT181      c_ttau  \\\n",
       "0  2035.000000   295.000000   8046.000000  702.000000  24.400000  598.000000   \n",
       "1  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
       "2  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
       "3  2397.612245   361.773196   9599.500000  790.090000  39.058000  418.709677   \n",
       "4  2752.976744   410.348837  11663.651163  964.255814  38.311628  393.948718   \n",
       "5  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
       "6  2397.612245   361.773196   9599.500000  790.090000  39.058000  418.709677   \n",
       "7  4626.000000   391.000000  11797.000000  936.000000  40.000000  310.000000   \n",
       "8  2397.612245   361.773196   9599.500000  790.090000  39.058000  418.709677   \n",
       "9  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
       "\n",
       "         c_NfL        c_GFAP     c_pT231   c_pT217  \n",
       "0   373.960000   8706.690000  487.340000  0.605900  \n",
       "1   735.907250   8163.845946  501.851892  1.254549  \n",
       "2   735.907250   8163.845946  501.851892  1.254549  \n",
       "3   780.569900   9070.057586  614.922874  2.080534  \n",
       "4   756.707209   8165.744286  525.304762  1.457107  \n",
       "5   735.907250   8163.845946  501.851892  1.254549  \n",
       "6   780.569900   9070.057586  614.922874  0.977400  \n",
       "7  1075.590000  37506.300000  609.430000  0.481200  \n",
       "8   780.569900   9070.057586  614.922874  2.080534  \n",
       "9   735.907250   8163.845946  501.851892  1.254549  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csfbiomk1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a38c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_strem2</th>\n",
       "      <th>c_PDGFRbeta</th>\n",
       "      <th>c_Ab40</th>\n",
       "      <th>c_Ab42</th>\n",
       "      <th>c_pT181</th>\n",
       "      <th>c_ttau</th>\n",
       "      <th>c_NfL</th>\n",
       "      <th>c_GFAP</th>\n",
       "      <th>c_pT231</th>\n",
       "      <th>c_pT217</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2035.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>8046.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>373.960000</td>\n",
       "      <td>8706.690000</td>\n",
       "      <td>487.340000</td>\n",
       "      <td>0.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2397.612245</td>\n",
       "      <td>361.773196</td>\n",
       "      <td>9599.500000</td>\n",
       "      <td>790.090000</td>\n",
       "      <td>39.058000</td>\n",
       "      <td>418.709677</td>\n",
       "      <td>780.569900</td>\n",
       "      <td>9070.057586</td>\n",
       "      <td>614.922874</td>\n",
       "      <td>2.080534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2752.976744</td>\n",
       "      <td>410.348837</td>\n",
       "      <td>11663.651163</td>\n",
       "      <td>964.255814</td>\n",
       "      <td>38.311628</td>\n",
       "      <td>393.948718</td>\n",
       "      <td>756.707209</td>\n",
       "      <td>8165.744286</td>\n",
       "      <td>525.304762</td>\n",
       "      <td>1.457107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      c_strem2  c_PDGFRbeta        c_Ab40      c_Ab42    c_pT181      c_ttau  \\\n",
       "0  2035.000000   295.000000   8046.000000  702.000000  24.400000  598.000000   \n",
       "1  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
       "2  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
       "3  2397.612245   361.773196   9599.500000  790.090000  39.058000  418.709677   \n",
       "4  2752.976744   410.348837  11663.651163  964.255814  38.311628  393.948718   \n",
       "\n",
       "        c_NfL       c_GFAP     c_pT231   c_pT217  \n",
       "0  373.960000  8706.690000  487.340000  0.605900  \n",
       "1  735.907250  8163.845946  501.851892  1.254549  \n",
       "2  735.907250  8163.845946  501.851892  1.254549  \n",
       "3  780.569900  9070.057586  614.922874  2.080534  \n",
       "4  756.707209  8165.744286  525.304762  1.457107  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean for each column, ignoring NaNs\n",
    "mean_values = csfbiomk1.mean()\n",
    "\n",
    "csfbiomk1 = csfbiomk1.fillna(mean_values)\n",
    "\n",
    "csfbiomk1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a5572bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling Neuropsychiatric Measurements\n",
    "\n",
    "briefa_file_path = r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\briefa_20231117.csv\"\n",
    "briefa = pd.read_csv(briefa_file_path)\n",
    "briefa = pd.DataFrame(briefa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90bdf10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in briefa:\n",
      "          Column  Number of Nulls\n",
      "0     subject_id                0\n",
      "1          visit                0\n",
      "2    checkin_bin                0\n",
      "3    exposurebin                0\n",
      "4     age_decade                0\n",
      "..           ...              ...\n",
      "102      workorg                0\n",
      "103    upseteasy                0\n",
      "104    impulsive                0\n",
      "105       pickup                0\n",
      "106     complete                0\n",
      "\n",
      "[107 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in each column\n",
    "briefa_nulls = briefa.isnull().sum()\n",
    "\n",
    "briefa_nulls_df = pd.DataFrame({\n",
    "    'Column': briefa_nulls.index,\n",
    "    'Number of Nulls': briefa_nulls.values\n",
    "})\n",
    "\n",
    "briefa_nulls_df_transposed = briefa_nulls_df.T\n",
    "\n",
    "print(\"Null values in briefa:\")\n",
    "print(briefa_nulls_df)\n",
    "briefa_nulls_df_transposed.to_csv(r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\briefa_nulls.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84cb4ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>visit</th>\n",
       "      <th>checkin_bin</th>\n",
       "      <th>exposurebin</th>\n",
       "      <th>age_decade</th>\n",
       "      <th>racecat_combined</th>\n",
       "      <th>eduyears</th>\n",
       "      <th>totyr_foot</th>\n",
       "      <th>chiiseas_pf</th>\n",
       "      <th>chiiyrs_pf</th>\n",
       "      <th>...</th>\n",
       "      <th>activityorg</th>\n",
       "      <th>getover</th>\n",
       "      <th>onething</th>\n",
       "      <th>moodchange</th>\n",
       "      <th>consequence</th>\n",
       "      <th>workorg</th>\n",
       "      <th>upseteasy</th>\n",
       "      <th>impulsive</th>\n",
       "      <th>pickup</th>\n",
       "      <th>complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4335.4</td>\n",
       "      <td>2167.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10363.1</td>\n",
       "      <td>5708.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6685.4</td>\n",
       "      <td>4863.9</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7701.2</td>\n",
       "      <td>6448.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  visit  checkin_bin  exposurebin  age_decade  racecat_combined  \\\n",
       "0        1001      1            2            1           1                 5   \n",
       "1        1002      1            2            1           1                 5   \n",
       "2        1003      1            2            1           1                 5   \n",
       "3        1004      1            1            1           2                 5   \n",
       "4        1005      1            3            0           2                 5   \n",
       "\n",
       "   eduyears  totyr_foot  chiiseas_pf  chiiyrs_pf  ...  activityorg  getover  \\\n",
       "0      16.0         7.0       4335.4      2167.7  ...            2        1   \n",
       "1      15.0        14.0      10363.1      5708.1  ...            3        3   \n",
       "2      18.0        12.0       6685.4      4863.9  ...            3        3   \n",
       "3      16.0        16.0       7701.2      6448.9  ...            1        1   \n",
       "4      21.0         NaN          NaN         NaN  ...            1        2   \n",
       "\n",
       "   onething  moodchange  consequence  workorg  upseteasy  impulsive  pickup  \\\n",
       "0         2           1            1        2          2          1       1   \n",
       "1         3           2            3        3          3          3       2   \n",
       "2         3           3            2        3          3          3       1   \n",
       "3         1           1            1        1          2          1       1   \n",
       "4         1           1            1        1          1          1       1   \n",
       "\n",
       "   complete  \n",
       "0         2  \n",
       "1         3  \n",
       "2         2  \n",
       "3         1  \n",
       "4         1  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "briefa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f47af536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi</th>\n",
       "      <th>tmi</th>\n",
       "      <th>gec</th>\n",
       "      <th>tgec</th>\n",
       "      <th>bri</th>\n",
       "      <th>tbri</th>\n",
       "      <th>inhibit</th>\n",
       "      <th>shift</th>\n",
       "      <th>emotcont</th>\n",
       "      <th>selfmon</th>\n",
       "      <th>initiate</th>\n",
       "      <th>workmem</th>\n",
       "      <th>planorg</th>\n",
       "      <th>taskmon</th>\n",
       "      <th>orgmat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>114</td>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>85</td>\n",
       "      <td>171</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>158</td>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>81</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>81</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mi  tmi  gec  tgec  bri  tbri  inhibit  shift  emotcont  selfmon  \\\n",
       "0   75   64  114    57   39    46       12      9        11        7   \n",
       "1  101   85  171    85   70    79       17     15        23       15   \n",
       "2   90   77  158    79   68    77       15     14        27       12   \n",
       "3   43   40   81    42   38    46        9      8        15        6   \n",
       "4   43   39   81    41   38    45        9     11        12        6   \n",
       "\n",
       "   initiate  workmem  planorg  taskmon  orgmat  \n",
       "0        14       17       20       13      11  \n",
       "1        19       24       27       15      16  \n",
       "2        20       22       22       14      12  \n",
       "3         9        8       11        7       8  \n",
       "4        10        8       10        7       8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "briefa = briefa.drop(columns=briefa.loc[:,'subject_id':'chiiyrs_pg'].columns)\n",
    "briefa = briefa.drop(columns=briefa.loc[:,'negativ':'complete'].columns)\n",
    "briefa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b971c900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi</th>\n",
       "      <th>tmi</th>\n",
       "      <th>gec</th>\n",
       "      <th>tgec</th>\n",
       "      <th>bri</th>\n",
       "      <th>tbri</th>\n",
       "      <th>inhibit</th>\n",
       "      <th>shift</th>\n",
       "      <th>emotcont</th>\n",
       "      <th>selfmon</th>\n",
       "      <th>initiate</th>\n",
       "      <th>workmem</th>\n",
       "      <th>planorg</th>\n",
       "      <th>taskmon</th>\n",
       "      <th>orgmat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.682203</td>\n",
       "      <td>56.724576</td>\n",
       "      <td>110.169492</td>\n",
       "      <td>56.508475</td>\n",
       "      <td>46.487288</td>\n",
       "      <td>55.203390</td>\n",
       "      <td>12.169492</td>\n",
       "      <td>9.690678</td>\n",
       "      <td>15.758475</td>\n",
       "      <td>8.868644</td>\n",
       "      <td>12.605932</td>\n",
       "      <td>13.758475</td>\n",
       "      <td>15.338983</td>\n",
       "      <td>9.466102</td>\n",
       "      <td>12.512712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.879120</td>\n",
       "      <td>16.771696</td>\n",
       "      <td>33.473344</td>\n",
       "      <td>17.217382</td>\n",
       "      <td>14.657067</td>\n",
       "      <td>16.438698</td>\n",
       "      <td>3.606861</td>\n",
       "      <td>3.378543</td>\n",
       "      <td>5.769042</td>\n",
       "      <td>3.063115</td>\n",
       "      <td>4.101039</td>\n",
       "      <td>4.922909</td>\n",
       "      <td>5.199379</td>\n",
       "      <td>2.946855</td>\n",
       "      <td>4.335387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>104.500000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.250000</td>\n",
       "      <td>68.250000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>67.250000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mi         tmi         gec        tgec         bri        tbri  \\\n",
       "count  236.000000  236.000000  236.000000  236.000000  236.000000  236.000000   \n",
       "mean    63.682203   56.724576  110.169492   56.508475   46.487288   55.203390   \n",
       "std     19.879120   16.771696   33.473344   17.217382   14.657067   16.438698   \n",
       "min     40.000000   36.000000   70.000000   35.000000   30.000000   36.000000   \n",
       "25%     45.000000   41.000000   79.750000   41.000000   34.000000   41.000000   \n",
       "50%     60.000000   53.000000  104.500000   54.000000   43.000000   51.000000   \n",
       "75%     79.250000   68.250000  136.000000   69.000000   57.000000   67.250000   \n",
       "max    116.000000  104.000000  204.000000  108.000000   88.000000  105.000000   \n",
       "\n",
       "          inhibit       shift    emotcont     selfmon    initiate     workmem  \\\n",
       "count  236.000000  236.000000  236.000000  236.000000  236.000000  236.000000   \n",
       "mean    12.169492    9.690678   15.758475    8.868644   12.605932   13.758475   \n",
       "std      3.606861    3.378543    5.769042    3.063115    4.101039    4.922909   \n",
       "min      8.000000    6.000000   10.000000    6.000000    8.000000    8.000000   \n",
       "25%      9.000000    6.000000   10.000000    6.000000    9.000000    9.000000   \n",
       "50%     11.000000    9.000000   14.000000    8.000000   12.000000   13.000000   \n",
       "75%     14.000000   12.000000   20.000000   11.000000   16.000000   18.000000   \n",
       "max     23.000000   18.000000   30.000000   18.000000   23.000000   24.000000   \n",
       "\n",
       "          planorg     taskmon      orgmat  \n",
       "count  236.000000  236.000000  236.000000  \n",
       "mean    15.338983    9.466102   12.512712  \n",
       "std      5.199379    2.946855    4.335387  \n",
       "min     10.000000    6.000000    8.000000  \n",
       "25%     10.000000    6.000000    9.000000  \n",
       "50%     14.000000    9.000000   11.000000  \n",
       "75%     19.250000   12.000000   15.000000  \n",
       "max     29.000000   18.000000   24.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "briefa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16c26d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 236 entries, 0 to 235\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   c_strem2     236 non-null    float64\n",
      " 1   c_PDGFRbeta  236 non-null    float64\n",
      " 2   c_Ab40       236 non-null    float64\n",
      " 3   c_Ab42       236 non-null    float64\n",
      " 4   c_pT181      236 non-null    float64\n",
      " 5   c_ttau       236 non-null    float64\n",
      " 6   c_NfL        236 non-null    float64\n",
      " 7   c_GFAP       236 non-null    float64\n",
      " 8   c_pT231      236 non-null    float64\n",
      " 9   c_pT217      236 non-null    float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 18.6 KB\n"
     ]
    }
   ],
   "source": [
    "csfbiomk1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab495d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "main_path = r'Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers'\n",
    "folder_name = 'blood_biomk1_to_briefa'  \n",
    "save_path = os.path.join(main_path, folder_name)\n",
    "os.makedirs(save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7ce67bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mi  tmi  gec  tgec  bri  tbri  inhibit  shift  emotcont  selfmon  \\\n",
      "0   75   64  114    57   39    46       12      9        11        7   \n",
      "1  101   85  171    85   70    79       17     15        23       15   \n",
      "2   90   77  158    79   68    77       15     14        27       12   \n",
      "3   43   40   81    42   38    46        9      8        15        6   \n",
      "4   43   39   81    41   38    45        9     11        12        6   \n",
      "\n",
      "   initiate  workmem  planorg  taskmon  orgmat  category  \n",
      "0        14       17       20       13      11         2  \n",
      "1        19       24       27       15      16         2  \n",
      "2        20       22       22       14      12         2  \n",
      "3         9        8       11        7       8         1  \n",
      "4        10        8       10        7       8         3  \n",
      "      c_strem2  c_PDGFRbeta        c_Ab40      c_Ab42    c_pT181      c_ttau  \\\n",
      "0  2035.000000   295.000000   8046.000000  702.000000  24.400000  598.000000   \n",
      "1  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
      "2  2683.750000   344.650000  10146.975000  863.500000  32.220000  401.702703   \n",
      "3  2397.612245   361.773196   9599.500000  790.090000  39.058000  418.709677   \n",
      "4  2752.976744   410.348837  11663.651163  964.255814  38.311628  393.948718   \n",
      "\n",
      "        c_NfL       c_GFAP     c_pT231   c_pT217  category  \n",
      "0  373.960000  8706.690000  487.340000  0.605900         2  \n",
      "1  735.907250  8163.845946  501.851892  1.254549         2  \n",
      "2  735.907250  8163.845946  501.851892  1.254549         2  \n",
      "3  780.569900  9070.057586  614.922874  2.080534         1  \n",
      "4  756.707209  8165.744286  525.304762  1.457107         3  \n"
     ]
    }
   ],
   "source": [
    "categories_file_path = r\"Z:\\Active-Diagnose_CTE\\Fargol_Analysis\\Neuropsychiatric_from_Biomarkers\\categories.csv\"\n",
    "categories_df = pd.read_csv(categories_file_path)\n",
    "new_column = categories_df['checkin_bin']\n",
    "briefa['category'] = new_column\n",
    "print(briefa.head())\n",
    "\n",
    "csfbiomk1['category'] = new_column\n",
    "print(csfbiomk1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "103b2738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csfbiomk1['category'] = briefa['category']\n",
    "\n",
    "# correlation_matrix = csfbiomk1.corr()\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True)\n",
    "# plt.title('Correlation Heatmap of Features')\n",
    "# plt.show()\n",
    "\n",
    "# # Alternatively, scatter plots for each feature vs y (checkin_bin)\n",
    "# for feature in csfbiomk1.columns[:-1]:  # Exclude the label column\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.boxplot(x='category', y=feature, data=csfbiomk1)\n",
    "#     plt.title(f'Boxplot of {feature} by category')\n",
    "#     plt.xlabel('category')\n",
    "#     plt.ylabel(feature)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44bd65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c6f4a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_strem2</th>\n",
       "      <th>c_PDGFRbeta</th>\n",
       "      <th>c_Ab40</th>\n",
       "      <th>c_Ab42</th>\n",
       "      <th>c_pT181</th>\n",
       "      <th>c_ttau</th>\n",
       "      <th>c_NfL</th>\n",
       "      <th>c_GFAP</th>\n",
       "      <th>c_pT231</th>\n",
       "      <th>c_pT217</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2035.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>8046.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>373.960000</td>\n",
       "      <td>8706.690000</td>\n",
       "      <td>487.340000</td>\n",
       "      <td>0.605900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2397.612245</td>\n",
       "      <td>361.773196</td>\n",
       "      <td>9599.500000</td>\n",
       "      <td>790.090000</td>\n",
       "      <td>39.058000</td>\n",
       "      <td>418.709677</td>\n",
       "      <td>780.569900</td>\n",
       "      <td>9070.057586</td>\n",
       "      <td>614.922874</td>\n",
       "      <td>2.080534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2752.976744</td>\n",
       "      <td>410.348837</td>\n",
       "      <td>11663.651163</td>\n",
       "      <td>964.255814</td>\n",
       "      <td>38.311628</td>\n",
       "      <td>393.948718</td>\n",
       "      <td>756.707209</td>\n",
       "      <td>8165.744286</td>\n",
       "      <td>525.304762</td>\n",
       "      <td>1.457107</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>607.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>6679.000000</td>\n",
       "      <td>621.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>273.150000</td>\n",
       "      <td>954.370000</td>\n",
       "      <td>343.900000</td>\n",
       "      <td>0.572700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2231.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>9686.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>423.170000</td>\n",
       "      <td>3147.720000</td>\n",
       "      <td>340.060000</td>\n",
       "      <td>1.457107</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>987.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>5283.000000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>220.620000</td>\n",
       "      <td>1691.780000</td>\n",
       "      <td>183.410000</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3525.000000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>9057.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>954.590000</td>\n",
       "      <td>5463.900000</td>\n",
       "      <td>499.050000</td>\n",
       "      <td>2.080534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>3091.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>11078.000000</td>\n",
       "      <td>818.000000</td>\n",
       "      <td>43.700000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>580.630000</td>\n",
       "      <td>3599.320000</td>\n",
       "      <td>816.360000</td>\n",
       "      <td>0.952700</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_strem2  c_PDGFRbeta        c_Ab40      c_Ab42    c_pT181  \\\n",
       "0    2035.000000   295.000000   8046.000000  702.000000  24.400000   \n",
       "1    2683.750000   344.650000  10146.975000  863.500000  32.220000   \n",
       "2    2683.750000   344.650000  10146.975000  863.500000  32.220000   \n",
       "3    2397.612245   361.773196   9599.500000  790.090000  39.058000   \n",
       "4    2752.976744   410.348837  11663.651163  964.255814  38.311628   \n",
       "..           ...          ...           ...         ...        ...   \n",
       "231   607.000000   279.000000   6679.000000  621.000000  18.000000   \n",
       "232  2231.000000   351.000000   9686.000000  801.000000  26.200000   \n",
       "233   987.000000   201.000000   5283.000000  536.000000  12.900000   \n",
       "234  3525.000000   477.000000   9057.000000  810.000000  28.400000   \n",
       "235  3091.000000   408.000000  11078.000000  818.000000  43.700000   \n",
       "\n",
       "         c_ttau       c_NfL       c_GFAP     c_pT231   c_pT217  category  \n",
       "0    598.000000  373.960000  8706.690000  487.340000  0.605900         2  \n",
       "1    401.702703  735.907250  8163.845946  501.851892  1.254549         2  \n",
       "2    401.702703  735.907250  8163.845946  501.851892  1.254549         2  \n",
       "3    418.709677  780.569900  9070.057586  614.922874  2.080534         1  \n",
       "4    393.948718  756.707209  8165.744286  525.304762  1.457107         3  \n",
       "..          ...         ...          ...         ...       ...       ...  \n",
       "231  401.702703  273.150000   954.370000  343.900000  0.572700         2  \n",
       "232  348.000000  423.170000  3147.720000  340.060000  1.457107         3  \n",
       "233  401.702703  220.620000  1691.780000  183.410000  0.111200         2  \n",
       "234  186.000000  954.590000  5463.900000  499.050000  2.080534         1  \n",
       "235  329.000000  580.630000  3599.320000  816.360000  0.952700         3  \n",
       "\n",
       "[236 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csfbiomk1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca52a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0180ae7c",
   "metadata": {},
   "source": [
    "\n",
    "# 95th percentile for both analysis and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50a17bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in csfbiomk1.columns[:-1]:  # Assuming 'category' is the last column\n",
    "    upper_limit = csfbiomk1[feature].quantile(0.95)  # Cap at 95th percentile\n",
    "    lower_limit = csfbiomk1[feature].quantile(0.05)  # Floor at 5th percentile\n",
    "    csfbiomk1[feature] = np.where(csfbiomk1[feature] > upper_limit, upper_limit, csfbiomk1[feature])\n",
    "    csfbiomk1[feature] = np.where(csfbiomk1[feature] < lower_limit, lower_limit, csfbiomk1[feature])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38819f",
   "metadata": {},
   "source": [
    "# Initial Step for Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a2d78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = csfbiomk1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09f870dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_strem2</th>\n",
       "      <th>c_PDGFRbeta</th>\n",
       "      <th>c_Ab40</th>\n",
       "      <th>c_Ab42</th>\n",
       "      <th>c_pT181</th>\n",
       "      <th>c_ttau</th>\n",
       "      <th>c_NfL</th>\n",
       "      <th>c_GFAP</th>\n",
       "      <th>c_pT231</th>\n",
       "      <th>c_pT217</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2035.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>8046.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>373.960000</td>\n",
       "      <td>8706.690000</td>\n",
       "      <td>487.340000</td>\n",
       "      <td>0.605900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2683.750000</td>\n",
       "      <td>344.650000</td>\n",
       "      <td>10146.975000</td>\n",
       "      <td>863.500000</td>\n",
       "      <td>32.220000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>735.907250</td>\n",
       "      <td>8163.845946</td>\n",
       "      <td>501.851892</td>\n",
       "      <td>1.254549</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2397.612245</td>\n",
       "      <td>361.773196</td>\n",
       "      <td>9599.500000</td>\n",
       "      <td>790.090000</td>\n",
       "      <td>39.058000</td>\n",
       "      <td>418.709677</td>\n",
       "      <td>780.569900</td>\n",
       "      <td>9070.057586</td>\n",
       "      <td>614.922874</td>\n",
       "      <td>2.080534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2752.976744</td>\n",
       "      <td>410.348837</td>\n",
       "      <td>11663.651163</td>\n",
       "      <td>964.255814</td>\n",
       "      <td>38.311628</td>\n",
       "      <td>393.948718</td>\n",
       "      <td>756.707209</td>\n",
       "      <td>8165.744286</td>\n",
       "      <td>525.304762</td>\n",
       "      <td>1.457107</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1109.750000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>6679.000000</td>\n",
       "      <td>621.000000</td>\n",
       "      <td>19.575000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>273.150000</td>\n",
       "      <td>1900.257500</td>\n",
       "      <td>343.900000</td>\n",
       "      <td>0.572700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2231.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>9686.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>423.170000</td>\n",
       "      <td>3147.720000</td>\n",
       "      <td>340.060000</td>\n",
       "      <td>1.457107</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1109.750000</td>\n",
       "      <td>208.750000</td>\n",
       "      <td>5874.500000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>19.575000</td>\n",
       "      <td>401.702703</td>\n",
       "      <td>272.692500</td>\n",
       "      <td>1900.257500</td>\n",
       "      <td>278.202500</td>\n",
       "      <td>0.318225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3525.000000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>9057.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>189.500000</td>\n",
       "      <td>954.590000</td>\n",
       "      <td>5463.900000</td>\n",
       "      <td>499.050000</td>\n",
       "      <td>2.080534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>3091.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>11078.000000</td>\n",
       "      <td>818.000000</td>\n",
       "      <td>43.700000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>580.630000</td>\n",
       "      <td>3599.320000</td>\n",
       "      <td>816.360000</td>\n",
       "      <td>0.952700</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_strem2  c_PDGFRbeta        c_Ab40      c_Ab42    c_pT181  \\\n",
       "0    2035.000000   295.000000   8046.000000  702.000000  24.400000   \n",
       "1    2683.750000   344.650000  10146.975000  863.500000  32.220000   \n",
       "2    2683.750000   344.650000  10146.975000  863.500000  32.220000   \n",
       "3    2397.612245   361.773196   9599.500000  790.090000  39.058000   \n",
       "4    2752.976744   410.348837  11663.651163  964.255814  38.311628   \n",
       "..           ...          ...           ...         ...        ...   \n",
       "231  1109.750000   279.000000   6679.000000  621.000000  19.575000   \n",
       "232  2231.000000   351.000000   9686.000000  801.000000  26.200000   \n",
       "233  1109.750000   208.750000   5874.500000  536.000000  19.575000   \n",
       "234  3525.000000   477.000000   9057.000000  810.000000  28.400000   \n",
       "235  3091.000000   408.000000  11078.000000  818.000000  43.700000   \n",
       "\n",
       "         c_ttau       c_NfL       c_GFAP     c_pT231   c_pT217  category  \n",
       "0    598.000000  373.960000  8706.690000  487.340000  0.605900         2  \n",
       "1    401.702703  735.907250  8163.845946  501.851892  1.254549         2  \n",
       "2    401.702703  735.907250  8163.845946  501.851892  1.254549         2  \n",
       "3    418.709677  780.569900  9070.057586  614.922874  2.080534         1  \n",
       "4    393.948718  756.707209  8165.744286  525.304762  1.457107         3  \n",
       "..          ...         ...          ...         ...       ...       ...  \n",
       "231  401.702703  273.150000  1900.257500  343.900000  0.572700         2  \n",
       "232  348.000000  423.170000  3147.720000  340.060000  1.457107         3  \n",
       "233  401.702703  272.692500  1900.257500  278.202500  0.318225         2  \n",
       "234  189.500000  954.590000  5463.900000  499.050000  2.080534         1  \n",
       "235  329.000000  580.630000  3599.320000  816.360000  0.952700         3  \n",
       "\n",
       "[236 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08314cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# got error due to non numeric values, so removing them:\n",
    "\n",
    "# Assume csfbiomk1 is your DataFrame loaded with various types of data\n",
    "X = csfbiomk1.copy()\n",
    "\n",
    "# Select only numeric columns from the DataFrame\n",
    "X_numeric = X.select_dtypes(include=[np.number])\n",
    "X = X_numeric\n",
    "\n",
    "# Now X_numeric contains only the numeric columns of the original DataFrame\n",
    "# Proceed with scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test = train_test_split(X_scaled, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "\n",
    "X_train, X_test = train_test_split(X_scaled, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd00cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns you want to select for modeling\n",
    "## columns = ['mi', 'tmi','gec','tgec','bri','tbri','inhibit','shift','emotcont','selfmon','initiate','workmem','planorg','taskmon','orgmat'] \n",
    "selected_columns = ['orgmat']  # Replace 'column1' and 'column2' with the actual column names\n",
    "\n",
    "# selected_columns = ['mi', 'tmi','gec','tgec','bri','tbri','inhibit','shift','emotcont','selfmon','initiate','workmem','planorg','taskmon','orgmat']  # Replace 'column1' and 'column2' with the actual column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07f9aa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orgmat']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70beb6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to feature_importance_rankings.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Random Forest\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# First, calculate feature importances for each target column and save rankings\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train full model to get feature importances\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get feature importance and rank features\n",
    "    feature_importance = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "    ranked_features = feature_importance.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Save performance metrics with all features as a baseline\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate model with selected features\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to feature_importance_rankings.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ef49486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Multiple Linear Regression\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Standardize features for linear regression\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# First, calculate feature importances using SelectKBest for each target column and save rankings\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train full model with all features as a baseline\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate and store baseline performance metrics with all features\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate model with selected features\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb96033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 407\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 88\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 210\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 249\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 288\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 328\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 366\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 407\n",
      "[LightGBM] [Info] Number of data points in the train set: 165, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 12.466667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Gradient Boosting Machines\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# First, calculate feature importances using SelectKBest for each target column and save rankings\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train full model with all features as a baseline\n",
    "    model = LGBMRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate and store baseline performance metrics with all features\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate model with selected features\n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b43ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"XGBoost\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# First, calculate feature importances using SelectKBest for each target column and save rankings\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train full model with all features as a baseline\n",
    "    model = xgb.XGBRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate and store baseline performance metrics with all features\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate model with selected features\n",
    "        model = xgb.XGBRegressor(random_state=42)\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d010d136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Support Vector Regression\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Standardize features for SVR\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Calculate feature importances using SelectKBest for each target column and save rankings\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train SVR model with all features as a baseline\n",
    "    model = SVR(kernel='rbf', C=0.2, epsilon=0.01)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate and store baseline performance metrics with all features\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate model with selected features\n",
    "        model = SVR(kernel='rbf', C=0.2, epsilon=0.01)\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28cba56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 997us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 998us/step\n",
      "3/3 [==============================] - 0s 641us/step\n",
      "3/3 [==============================] - 0s 997us/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F75387ADD0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F756B60310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 499us/step\n",
      "3/3 [==============================] - 0s 999us/step\n",
      "3/3 [==============================] - 0s 998us/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 998us/step\n",
      "3/3 [==============================] - 0s 998us/step\n",
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"ANN\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Standardize features for ANN\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Feature selection and baseline model training\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train ANN model with all features as a baseline\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=X_train_selected.shape[1]),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train_selected, y_train, epochs=100, batch_size=10, verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(X_test_selected).flatten()\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Scale selected features for ANN\n",
    "        X_train_selected_scaled = scaler.fit_transform(X_train_selected)\n",
    "        X_test_selected_scaled = scaler.transform(X_test_selected)\n",
    "        \n",
    "        # Train and evaluate ANN model with selected features\n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', input_dim=X_train_selected_scaled.shape[1]),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X_train_selected_scaled, y_train, epochs=100, batch_size=10, verbose=0)\n",
    "        \n",
    "        y_pred = model.predict(X_test_selected_scaled).flatten()\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bd72f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"KNeighbors Regressor\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Standardize features for KNN\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Feature selection and baseline model training\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train KNN model with all features as a baseline\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    model = KNeighborsRegressor(n_neighbors=5)\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate KNN model with selected features\n",
    "        model = KNeighborsRegressor(n_neighbors=5)\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "294b6b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Stacking Regressor\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Define the base models and final estimator for stacking\n",
    "base_models = [\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=13, leaf_size=23, p=1, weights='uniform')),\n",
    "    ('svr', SVR(kernel='rbf', C=0.2, epsilon=0.01))\n",
    "]\n",
    "final_estimator = Ridge()\n",
    "stack_model = StackingRegressor(estimators=base_models, final_estimator=final_estimator, cv=5)\n",
    "\n",
    "# Feature selection and baseline model training\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train stacking model with all features as a baseline\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    stack_model.fit(X_train_selected, y_train)\n",
    "    y_pred = stack_model.predict(X_test_selected)\n",
    "    \n",
    "    # Evaluate and store baseline performance metrics with all features\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate stacking model with selected features\n",
    "        stack_model.fit(X_train_selected, y_train)\n",
    "        y_pred = stack_model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aec7c9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Bagging with SVR\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Define the base model for Bagging\n",
    "base_model = SVR(kernel='rbf', C=0.2, epsilon=0.01)\n",
    "\n",
    "# Feature selection and baseline model training\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train Bagging model with all features as a baseline\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    bagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, n_jobs=-1)\n",
    "    bagging_model.fit(X_train_selected, y_train)\n",
    "    y_pred = bagging_model.predict(X_test_selected)\n",
    "    \n",
    "    # Evaluate and store baseline performance metrics with all features\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate Bagging model with selected features\n",
    "        bagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, n_jobs=-1)\n",
    "        bagging_model.fit(X_train_selected, y_train)\n",
    "        y_pred = bagging_model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "628de5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Bagging with SVR\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Define the base model for Bagging\n",
    "base_model = SVR(kernel='rbf', C=0.2, epsilon=0.01)\n",
    "\n",
    "# Feature selection and baseline model training\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train Bagging model with all features as a baseline\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    bagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, n_jobs=-1)\n",
    "    bagging_model.fit(X_train_selected, y_train)\n",
    "    y_pred = bagging_model.predict(X_test_selected)\n",
    "    \n",
    "    # Evaluate and store baseline performance metrics with all features\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate Bagging model with selected features\n",
    "        bagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42, n_jobs=-1)\n",
    "        bagging_model.fit(X_train_selected, y_train)\n",
    "        y_pred = bagging_model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f0979a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Lasso Regression\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Standardize features for Lasso regression\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Feature ranking and baseline model training\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Lasso Regression Model with L1 regularization for feature selection\n",
    "    model = Lasso(alpha=0.1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Select features based on non-zero coefficients\n",
    "    selector = SelectFromModel(model, prefit=True)\n",
    "    selected_features = X_train.columns[selector.get_support()]\n",
    "    \n",
    "    # Feature importance ranking based on absolute Lasso coefficients\n",
    "    feature_importance = pd.Series(abs(model.coef_), index=X_train.columns)\n",
    "    ranked_features = feature_importance.sort_values(ascending=False)\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "\n",
    "    # Evaluate baseline performance with all features\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select top `n_features` based on ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate model with selected features\n",
    "        model = Lasso(alpha=0.1)\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aeecddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Initialize lists and dictionaries to store results and feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Ridge Regression\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Standardize features for Ridge regression\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Feature ranking and baseline model training\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Ridge Regression Model\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use coefficients for feature importance\n",
    "    feature_importance = pd.Series(abs(model.coef_), index=X_train.columns)\n",
    "    ranked_features = feature_importance.sort_values(ascending=False)\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Evaluate baseline performance with all features\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select top `n_features` based on ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate model with selected features\n",
    "        model = Ridge(alpha=1.0)\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "112d9cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize lists and dictionaries for storing results and feature rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Bayesian Ridge\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Standardize features for consistency\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Feature ranking and baseline model training\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train full model to get feature importances\n",
    "    model = BayesianRidge()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use coefficients for feature importance ranking\n",
    "    feature_importance = pd.Series(abs(model.coef_), index=X_train.columns)\n",
    "    ranked_features = feature_importance.sort_values(ascending=False)\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Baseline performance with all features\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select top `n_features` based on ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate model with selected features\n",
    "        model = BayesianRidge()\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0464b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\fargor\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance rankings saved to Feature_Importance_rank.xlsx\n",
      "Performance metrics with varying top features saved to performance_with_top_features.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Initialize an empty list to store results and a dictionary for feature importance rankings\n",
    "results = []\n",
    "feature_importance_rankings = {}\n",
    "model_name = \"Gaussian Process Regression\"\n",
    "selected_columns_str = \"_\".join(selected_columns)\n",
    "\n",
    "# Define the kernel\n",
    "kernel = RBF(1.0)\n",
    "\n",
    "# Standardize features for Gaussian Process Regression\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# First, calculate feature importances using SelectKBest for each target column and save rankings\n",
    "for column in selected_columns:\n",
    "    y = briefa[column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=\"all\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "    ranked_features = feature_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Save the rankings in a dictionary\n",
    "    feature_importance_rankings[column] = ranked_features\n",
    "    \n",
    "    # Train the full Gaussian Process model as a baseline\n",
    "    model = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate and store baseline performance with all features\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Column\": column,\n",
    "        \"Top Features\": \"All\",\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "\n",
    "# Save feature importance rankings to an Excel file\n",
    "with pd.ExcelWriter(f\"Feature_Importance_csfbiomk1_rank_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    for column, ranking in feature_importance_rankings.items():\n",
    "        ranking_sorted = ranking.sort_values(ascending=False)\n",
    "        ranking_sorted.to_excel(writer, sheet_name=f\"{model_name}_{column}\")\n",
    "\n",
    "# Test different numbers of top features and evaluate model performance\n",
    "max_features_to_test = X.shape[1]  # Test from 1 up to the total number of features\n",
    "\n",
    "for n_features in range(1, max_features_to_test + 1):\n",
    "    for column in selected_columns:\n",
    "        y = briefa[column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Select the top `n_features` based on initial ranking\n",
    "        top_features = feature_importance_rankings[column].nlargest(n_features).index\n",
    "        X_train_selected = X_train[top_features]\n",
    "        X_test_selected = X_test[top_features]\n",
    "        \n",
    "        # Train and evaluate model with selected features\n",
    "        model = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results for each number of top features\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Column\": column,\n",
    "            \"Top Features\": n_features,\n",
    "            \"Mean Squared Error\": mse,\n",
    "            \"Mean Absolute Error\": mae,\n",
    "            \"R^2 Score\": r2\n",
    "        })\n",
    "\n",
    "# Save all results to an Excel file\n",
    "results_df = pd.DataFrame(results)\n",
    "with pd.ExcelWriter(f\"performance_csfbiomk1_w_top_features_{selected_columns_str}.xlsx\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=model_name)\n",
    "\n",
    "print(\"Feature importance rankings saved to Feature_Importance_rank.xlsx\")\n",
    "print(\"Performance metrics with varying top features saved to performance_with_top_features.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b09f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
